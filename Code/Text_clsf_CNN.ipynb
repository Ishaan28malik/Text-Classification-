{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nnq2trgcQ5Oq"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHyNwZeljT1h"
   },
   "source": [
    "**Since new version for Tensorflow is available so we import the backend data and new files for v2(version 2) into v1(version 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8dM4dVMcxWV"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4VIWg9tjdsp"
   },
   "source": [
    "# Reading data from the CSV file using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "P3JM7JiPc3d5",
    "outputId": "165ee4fe-1f4c-4416-d068-b8bb94763992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  ... Unnamed: 4\n",
       "0   ham  ...        NaN\n",
       "1   ham  ...        NaN\n",
       "2  spam  ...        NaN\n",
       "3   ham  ...        NaN\n",
       "4   ham  ...        NaN\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../spam.csv',delimiter=',',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDphTuy4zMTU"
   },
   "source": [
    "# Dropping the outliers or unecessary empty data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "e65HyT_xfmFb",
    "outputId": "91d1eacf-3f4c-42f9-9b7f-55b8ad662206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "v1    5572 non-null object\n",
      "v2    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_ya6biZzOCq"
   },
   "source": [
    "# Creating the plot for the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Vc3VrV6ifqEW",
    "outputId": "f3710971-22a3-4b76-9271-2b14c5cc66a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j+jWrlDG/6OSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.v1)\n",
    "plt.xlabel('CATEGORY')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQNSENZPzZ2l"
   },
   "source": [
    "**Labeling and creating Input and Output vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17TKrsK4fuyZ"
   },
   "outputs": [],
   "source": [
    "X = df.v2\n",
    "Y = df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIQfDrm4zaxk"
   },
   "source": [
    "**Data splitting into test and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okAPlrf4fweY"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9p1eQ3hzeUS"
   },
   "source": [
    "# Data processing \n",
    "* Tokenize the data\n",
    "* Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0FxvVIP4c5k2",
    "outputId": "08a183b3-6264-4eac-e311-2d9154d8749f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1  ... Unnamed: 4\n",
      "0   ham  ...        NaN\n",
      "1   ham  ...        NaN\n",
      "2  spam  ...        NaN\n",
      "3   ham  ...        NaN\n",
      "4   ham  ...        NaN\n",
      "\n",
      "[5 rows x 5 columns]\n",
      "import done\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = '../spam.csv'\n",
    "df = pd.read_csv(DATA_FILE,encoding='latin-1')\n",
    "print(df.head())\n",
    "\n",
    "tags = df.v1\n",
    "texts = df.v2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAh4pQM7d9BH"
   },
   "outputs": [],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NW0ived4eHdI"
   },
   "outputs": [],
   "source": [
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)\n",
    "\n",
    "m = get_simple_model()\n",
    "check_model(m,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odfOHWhnzyp3"
   },
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "NcVhv-h4eMIN",
    "outputId": "450f583e-903f-41d3-d218-69459a0b4436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 469, 841, 751, 657, 64, 8, 89, 121, 349, 147, 67, 58, 144]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  50 469 841 751\n",
      " 657  64   8  89 121 349 147  67  58 144]\n",
      "(5572, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DE_g1jkGz2iN"
   },
   "source": [
    "**Model v1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "nfSutYJyefnB",
    "outputId": "aa961175-c5fc-4446-9084-61d8746733f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 2s 449us/step - loss: 0.3918 - acc: 0.8638 - binary_accuracy: 0.8638 - val_loss: 0.2852 - val_acc: 0.8700 - val_binary_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 1s 287us/step - loss: 0.1819 - acc: 0.9282 - binary_accuracy: 0.9282 - val_loss: 0.0839 - val_acc: 0.9731 - val_binary_accuracy: 0.9731\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 1s 288us/step - loss: 0.0596 - acc: 0.9829 - binary_accuracy: 0.9829 - val_loss: 0.0537 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 1s 286us/step - loss: 0.0347 - acc: 0.9899 - binary_accuracy: 0.9899 - val_loss: 0.0490 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 1s 283us/step - loss: 0.0221 - acc: 0.9942 - binary_accuracy: 0.9942 - val_loss: 0.0489 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 1s 282us/step - loss: 0.0163 - acc: 0.9951 - binary_accuracy: 0.9951 - val_loss: 0.0607 - val_acc: 0.9776 - val_binary_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 1s 283us/step - loss: 0.0103 - acc: 0.9975 - binary_accuracy: 0.9975 - val_loss: 0.0634 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 1s 282us/step - loss: 0.0073 - acc: 0.9975 - binary_accuracy: 0.9975 - val_loss: 0.0615 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 1s 301us/step - loss: 0.0058 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.0663 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 1s 295us/step - loss: 0.0047 - acc: 0.9984 - binary_accuracy: 0.9984 - val_loss: 0.0714 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v1()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFrA4doPz8r_"
   },
   "source": [
    "**Model v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "kG9UMVHxejtc",
    "outputId": "f0260f8b-5e20-4929-88c0-74b0c1581fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 3s 625us/step - loss: 0.3761 - acc: 0.8591 - binary_accuracy: 0.8591 - val_loss: 0.2550 - val_acc: 0.8700 - val_binary_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 2s 438us/step - loss: 0.1069 - acc: 0.9679 - binary_accuracy: 0.9679 - val_loss: 0.0487 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 2s 440us/step - loss: 0.0350 - acc: 0.9890 - binary_accuracy: 0.9890 - val_loss: 0.0487 - val_acc: 0.9839 - val_binary_accuracy: 0.9839\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 2s 441us/step - loss: 0.0199 - acc: 0.9946 - binary_accuracy: 0.9946 - val_loss: 0.0531 - val_acc: 0.9865 - val_binary_accuracy: 0.9865\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 2s 440us/step - loss: 0.0122 - acc: 0.9966 - binary_accuracy: 0.9966 - val_loss: 0.0651 - val_acc: 0.9794 - val_binary_accuracy: 0.9794\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 2s 436us/step - loss: 0.0086 - acc: 0.9982 - binary_accuracy: 0.9982 - val_loss: 0.0620 - val_acc: 0.9857 - val_binary_accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 2s 438us/step - loss: 0.0048 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.0750 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 2s 445us/step - loss: 0.0041 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.0743 - val_acc: 0.9830 - val_binary_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 2s 443us/step - loss: 0.0032 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0783 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 2s 440us/step - loss: 0.0019 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.0856 - val_acc: 0.9803 - val_binary_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v2(): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v2()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1KnWIz40EAy"
   },
   "source": [
    "**Model v3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "4OFK4njgg729",
    "outputId": "30f93e5d-0576-40d5-ec71-e1e3bf6b375b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 98, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4457 samples, validate on 1115 samples\n",
      "Epoch 1/10\n",
      "4457/4457 [==============================] - 4s 794us/step - loss: 0.3541 - acc: 0.8600 - binary_accuracy: 0.8600 - val_loss: 0.2544 - val_acc: 0.8700 - val_binary_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "4457/4457 [==============================] - 3s 594us/step - loss: 0.1737 - acc: 0.9331 - binary_accuracy: 0.9331 - val_loss: 0.0632 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 3/10\n",
      "4457/4457 [==============================] - 3s 602us/step - loss: 0.0460 - acc: 0.9879 - binary_accuracy: 0.9879 - val_loss: 0.0527 - val_acc: 0.9821 - val_binary_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "4457/4457 [==============================] - 3s 603us/step - loss: 0.0289 - acc: 0.9915 - binary_accuracy: 0.9915 - val_loss: 0.0612 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 5/10\n",
      "4457/4457 [==============================] - 3s 602us/step - loss: 0.0176 - acc: 0.9946 - binary_accuracy: 0.9946 - val_loss: 0.0680 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 6/10\n",
      "4457/4457 [==============================] - 3s 599us/step - loss: 0.0118 - acc: 0.9962 - binary_accuracy: 0.9962 - val_loss: 0.0741 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "4457/4457 [==============================] - 3s 594us/step - loss: 0.0072 - acc: 0.9982 - binary_accuracy: 0.9982 - val_loss: 0.0815 - val_acc: 0.9848 - val_binary_accuracy: 0.9848\n",
      "Epoch 8/10\n",
      "4457/4457 [==============================] - 3s 593us/step - loss: 0.0052 - acc: 0.9982 - binary_accuracy: 0.9982 - val_loss: 0.0972 - val_acc: 0.9740 - val_binary_accuracy: 0.9740\n",
      "Epoch 9/10\n",
      "4457/4457 [==============================] - 3s 596us/step - loss: 0.0058 - acc: 0.9987 - binary_accuracy: 0.9987 - val_loss: 0.1013 - val_acc: 0.9812 - val_binary_accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "4457/4457 [==============================] - 3s 600us/step - loss: 0.0054 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.1098 - val_acc: 0.9785 - val_binary_accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v3()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOnHHHsT0OHL"
   },
   "source": [
    "**Test data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bz34TFwafZty"
   },
   "outputs": [],
   "source": [
    " test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BgmXc8i0T60"
   },
   "source": [
    "**Test data evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NrQ-YDbQf9fF",
    "outputId": "53cda7f8-b65b-4a39-93c1-e5d81193ff40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 0s 154us/step\n"
     ]
    }
   ],
   "source": [
    "accr = m.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioX2HqQh0bpD"
   },
   "source": [
    "# **Print the final result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m8CpBvBYf_fV",
    "outputId": "a51577f5-d7b1-474a-8c83-3ef97fc777c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.043\n",
      "  Accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hjrg8ReQgZec"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text-clsf-CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
